{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f364860",
   "metadata": {},
   "source": [
    "# Importing modules and lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f174931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random as random\n",
    "import re\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from MY_FUNCTIONS import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee7ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv('/home/inous/Documents/S2/INRIA/LEXIQUE/Lexique383/Lexique383.tsv', sep='\\t')\n",
    "lexicon = lexicon[['ortho', 'nbsyll']]\n",
    "dictionnary = dict(zip(lexicon['ortho'], lexicon ['nbsyll']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e237a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_path = \"/home/inous/Documents/S2/INRIA/PLOTS2/\"\n",
    "#directory to stock all the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0d6fa",
   "metadata": {},
   "source": [
    "# Defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13978085",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_silences = 0  #silences between words of a same utterance\n",
    "remove_shorter = 1  #utterances with only one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd2c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_red = (0.8,0,0)\n",
    "my_blue= (0,0.4,0.8)\n",
    "my_pink = (1,0.4,0.4)\n",
    "my_green = (0,0.8,0.4)\n",
    "my_purple = (0.6,0,0.3)\n",
    "my_yellow = (0.89, 0.75, 0)\n",
    "my_orange = (0.82, 0.55, 0)\n",
    "my_turquoise = (0, 0.72, 0.58)\n",
    "my_bordeaux = (0.51, 0.02, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192cfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = [my_red, my_blue, my_pink, my_green, my_purple, my_yellow, my_orange, my_turquoise, my_bordeaux]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c61d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_window = 9\n",
    "default_poly = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb66faa",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db85a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = pd.read_csv(\"/home/inous/Documents/S2/INRIA/ALIGNED/word.csv\")\n",
    "WORDS = WORDS[ WORDS['Length']!=0] #to keep only non-zero intervals\n",
    "filenames = WORDS['Filename'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25dbaf",
   "metadata": {},
   "source": [
    "# Separating AA and CA files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a59de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_AA = []\n",
    "WORDS_CA = []\n",
    "for filename in filenames : \n",
    "    WORDS_file = WORDS[ WORDS['Filename']==filename][['Word','UtteranceName','Speaker', 'Length', 'Global_start', 'Filename', 'Global_end']]\n",
    "    WORDS_file.reset_index(drop=True, inplace=True)\n",
    "    WORDS_file=WORDS_file.sort_values('Speaker', ascending=True)\n",
    "    if filename[0:2]=='AA':\n",
    "        WORDS_AA.append(WORDS_file)\n",
    "    else:\n",
    "        WORDS_CA.append(WORDS_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415dce7",
   "metadata": {},
   "source": [
    "# Creating a csv file for each conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915fa4a",
   "metadata": {},
   "source": [
    "## Computing the \"syllables\" column, and grouping words by utterances (keeping the first start and last end, summing syllables and length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "125503da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,WORDS in enumerate(WORDS_AA) :\n",
    "        \n",
    "    list_syll = []\n",
    "    for word in WORDS['Word']:\n",
    "        word=word.lower()\n",
    "        if word in dictionnary:\n",
    "            list_syll.append(dictionnary[word])\n",
    "        else : \n",
    "            list_syll.append(estimate_syll(word))\n",
    "            \n",
    "    WORDS[\"syllables\"] = list_syll\n",
    "    WORDS=WORDS.sort_values('Global_start', ascending=True)\n",
    "    WORDS_AA[i] = WORDS\n",
    "        \n",
    "    table = pd.pivot_table(WORDS, values = ['Length', 'Global_start', 'Global_end','syllables', 'Speaker', 'Filename', 'Word'], index = ['UtteranceName'], aggfunc = {'Length':np.sum, 'Global_start':min, 'syllables':np.sum, 'Speaker' : np.min, 'Filename':np.min, 'Word':'count', 'Global_end':max})\n",
    "    table = table.sort_values('Global_start', ascending = True)\n",
    "    if remove_silences:\n",
    "        table['Speech rate'] = table['syllables']/table['Length']\n",
    "    else:\n",
    "        table['Speech rate'] = table['syllables']/(table['Global_end']-table['Global_start'])\n",
    "    if remove_shorter:\n",
    "        table = table[ table['Word']>1]\n",
    "    WORDS_AA[i] = table\n",
    "    table.to_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/'+str(WORDS['Filename'][0])+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac5145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,WORDS in enumerate(WORDS_CA) : \n",
    "        \n",
    "    list_syll = []\n",
    "    for word in WORDS['Word']:\n",
    "        word=str(word)\n",
    "        word = word.lower()\n",
    "        if word in dictionnary:\n",
    "            list_syll.append(dictionnary[word])\n",
    "        else : \n",
    "            list_syll.append(estimate_syll(word))\n",
    "    WORDS[\"syllables\"] = list_syll\n",
    "    WORDS_CA[i] = WORDS\n",
    "    \n",
    "    WORDS['Word'] = np.vectorize(str)(WORDS['Word'])\n",
    "    WORDS.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    table = pd.pivot_table(WORDS, values = ['Word', 'UtteranceName', 'Global_start', 'Global_end', 'Length', \"Filename\", \"syllables\"], index = ['UtteranceName', \"Speaker\"], aggfunc = {\"Global_end\":max,\"UtteranceName\":np.unique,'Word':'count', 'Global_start':min, \"Length\":sum, \"Speaker\":np.unique, \"Filename\":np.unique, \"syllables\":sum})    \n",
    "    table = table.sort_values('Global_start', ascending = True)\n",
    "    \n",
    "    if remove_silences :\n",
    "        table['Speech rate'] = table['syllables']/table['Length']\n",
    "    else : \n",
    "        table['Speech rate'] = table['syllables']/(table['Global_end']-table['Global_start'])\n",
    "    if remove_shorter:\n",
    "        table = table[ table['Word']>1]\n",
    "    WORDS_CA[i] = table\n",
    "    \n",
    "    table.to_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/'+str(WORDS['Filename'][0])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e84dbf",
   "metadata": {},
   "source": [
    "# Importing the new csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f44ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-LD-BF.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-MG-CH.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-MJ-CJ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-JL-AZ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-GD-DD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-XA-EH.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-AN-DL.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-ML-MP.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA/AA-LA-AN.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_AA = Path(\"/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/AA\").glob('**/*.csv')\n",
    "data_AA = []\n",
    "filenames_AA = []\n",
    "\n",
    "for path in pathlist_AA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        filenames_AA.append(str(path)[-12:-4])\n",
    "        data_AA.append(pd.read_csv(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4cf5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-XA-LA.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-MB-LB.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-LJ-MJ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-MD-GD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-FB-MG.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-RL-ML.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-JL-JT.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-LD-GD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA/CA-AN-ZN.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_CA = Path(\"/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ALIGNED/CA\").glob('**/*.csv')\n",
    "data_CA = []\n",
    "filenames_CA = []\n",
    "\n",
    "for path in pathlist_CA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        filenames_CA.append(str(path)[-12:-4])\n",
    "        data_CA.append(pd.read_csv(path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62f410",
   "metadata": {},
   "source": [
    "# Raw speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8680b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs1 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, data in enumerate(data_AA) :\n",
    "    \n",
    "    data_1 = data[ data['Speaker'] == \"Adult1\" ]\n",
    "    data_2 = data[ data['Speaker'] == \"Adult2\" ]\n",
    "    \n",
    "    axs1[i//3,i%3].set_title(data['Filename'][0])\n",
    "    axs1[i//3,i%3].set_xlabel('Time (sec)')\n",
    "    axs1[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs1[i//3,i%3].plot(data_1['Global_start'], data_1['Speech rate'], label=\"Adult1\", color=my_blue)\n",
    "    axs1[i//3,i%3].plot(data_2['Global_start'], data_2['Speech rate'], label=\"Adult2\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig1)\n",
    "fig1.savefig(plots_path+\"Raw AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, data in enumerate(data_CA) :\n",
    "    \n",
    "    data_1 = data[ data['Speaker'] == \"Parent\" ]\n",
    "    data_2 = data[ data['Speaker'] == \"Child\" ]\n",
    "    \n",
    "    axs2[i//3,i%3].set_title(data['Filename'][0])\n",
    "    axs2[i//3,i%3].set_xlabel('Time (sec)')\n",
    "    axs2[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs2[i//3,i%3].plot(data_1['Global_start'], data_1['Speech rate'], label=\"Parent\", color=my_blue)\n",
    "    axs2[i//3,i%3].plot(data_2['Global_start'], data_2['Speech rate'], label=\"Child\", color=my_red)\n",
    "    \n",
    "fig2.tight_layout()\n",
    "plt.close(fig2)\n",
    "fig2.savefig(plots_path+\"Raw CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635eb09a",
   "metadata": {},
   "source": [
    "# Fourier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a19090",
   "metadata": {},
   "source": [
    "# Smoothed speech rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77446ff5",
   "metadata": {},
   "source": [
    "## With a smoothing window of 10 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea446984",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axs3 = plt.subplots(3, 3, figsize=(20,17))\n",
    "\n",
    "for i, table in enumerate(data_AA) :\n",
    "    \n",
    "    axs3[i//3,i%3].set_xlabel('time')\n",
    "    axs3[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs3[i//3,i%3].plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], 29, 3), label='Adult1',color = my_red)\n",
    "    axs3[i//3,i%3].plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], 29, 3), label='Adult2', color=my_blue)\n",
    "    axs3[i//3,i%3].set_title(str(table['Filename'][0]))\n",
    "    axs3[i//3,i%3].legend()\n",
    "    \n",
    "    if \"AA-LD-BF\" in filenames_AA[i]:\n",
    "        fig35 = plt.figure()\n",
    "        plt.plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], 29, 3), label='Adult1',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], 29, 3), label='Adult2', color=my_blue)\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Speech rate (syllables/s)\")\n",
    "        plt.close(fig35)\n",
    "        fig35.savefig(examples_path+\"Smoothed AA\")\n",
    "    \n",
    "fig3.tight_layout()\n",
    "plt.close(fig3)\n",
    "fig3.savefig(test_path+\"Smoothed AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a68e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axs4 = plt.subplots(3, 3, figsize=(20,15))\n",
    "\n",
    "for i, table in enumerate(data_CA) :\n",
    "    \n",
    "    axs4[i//3,i%3].set_xlabel('time')\n",
    "    axs4[i//3,i%3].set_ylabel('Speech rate')\n",
    "    axs4[i//3,i%3].plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'],29, 3), label='Parent',color = my_red)\n",
    "    axs4[i//3,i%3].plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], 29, 3), label='Child', color=my_blue)\n",
    "    axs4[i//3,i%3].set_title(str(table['Filename'][0]))\n",
    "    axs4[i//3,i%3].legend()\n",
    "    \n",
    "    if \"CA-LD-GD\" in filenames_CA[i]:\n",
    "        fig45 = plt.figure()\n",
    "        plt.plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'], 29, 3), label='Parent',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], 29, 3), label='Child', color=my_blue)\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Speech rate (syllables/s)\")\n",
    "        plt.close(fig45)\n",
    "        fig45.savefig(examples_path+\"Smoothed CA\")\n",
    "    \n",
    "fig4.tight_layout()\n",
    "plt.close(fig4)\n",
    "fig4.savefig(plots_path+\"Smoothed CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04f3db",
   "metadata": {},
   "source": [
    "# \"Adapted\" speech rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d03b9",
   "metadata": {},
   "source": [
    "## To compute the correlation, the time series must have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb2f7a",
   "metadata": {},
   "source": [
    "### Loading manual phases notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb316fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_AA = \"/home/inous/Documents/S2/INRIA/DATA/MY_ANNOTATIONS_AA.txt\"\n",
    "text_AA = open(path_AA, 'r').read()\n",
    "\n",
    "lines_AA = text_AA.split('\\n')\n",
    "Filenames_AA = []\n",
    "Phases_AA = []\n",
    "line = lines_AA[0]\n",
    "file = []\n",
    "for line in lines_AA:\n",
    "    if line!='' and line!=' ':\n",
    "        if \"END\" not in line :\n",
    "            if \"FILENAME\" not in line:\n",
    "                label, time_string = line.split('[')\n",
    "                time_string = time_string.replace('[', '')\n",
    "                time_string = time_string.replace(']', '')\n",
    "                time_string = time_string.replace(' ', '')\n",
    "                time = conversion_time(time_string)\n",
    "                file.append([label, time])\n",
    "            else:\n",
    "                NOM, filename = line.split(' ')\n",
    "        else:\n",
    "            Filenames_AA.append(filename)\n",
    "            Phases_AA.append(file)\n",
    "            file=[]\n",
    "phases_AA = pd.DataFrame(list(zip(Filenames_AA, Phases_AA)), columns = ['Filename', 'Phases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe8ddd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CA = \"/home/inous/Documents/S2/INRIA/DATA/MY_ANNOTATIONS_CA.txt\"\n",
    "text_CA = open(path_CA, 'r').read()\n",
    "\n",
    "lines_CA = text_CA.split('\\n')\n",
    "Filenames_CA = []\n",
    "Phases_CA = []\n",
    "line = lines_CA[0]\n",
    "file = []\n",
    "for line in lines_CA:\n",
    "    if line!='' and line!=' ':\n",
    "        if \"END\" not in line :\n",
    "            if \"FILENAME\" not in line:\n",
    "                label, time_string = line.split('[')\n",
    "                time_string = time_string.replace('[', '')\n",
    "                time_string = time_string.replace(']', '')\n",
    "                time_string = time_string.replace(' ', '')\n",
    "                time = conversion_time(time_string)\n",
    "                file.append([label, time])\n",
    "            else:\n",
    "                NOM, filename = line.split(' ')\n",
    "        else:\n",
    "            Filenames_CA.append(filename)\n",
    "            Phases_CA.append(file)\n",
    "            file=[]\n",
    "phases_CA = pd.DataFrame(list(zip(Filenames_CA, Phases_CA)), columns = ['Filename', 'Phases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d71131",
   "metadata": {},
   "source": [
    "### Adding phases, roles and smoothed columns, save as csv, and adapt the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a3ad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA-LD-BF\n",
      "AA-MG-CH\n",
      "AA-MJ-CJ\n",
      "AA-JL-AZ\n",
      "AA-GD-DD\n",
      "AA-XA-EH\n",
      "AA-AN-DL\n",
      "AA-ML-MP\n",
      "AA-LA-AN\n"
     ]
    }
   ],
   "source": [
    "for i,filename in enumerate(filenames_AA):\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    data = data_AA[i]\n",
    "    \n",
    "    adapted_data = adapt_points_3(data,\"Speaker\", \"Global_start\", \"Speech rate\")\n",
    "    \n",
    "    liste_phases = list(phases_AA[phases_AA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    adapted_data['Phases'] = find_phases(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data['Roles'] = find_roles(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data[\"Word\"] = data[\"Word\"]\n",
    "    \n",
    "    adapted_data[\"smoothed\"] = smoothed_column(adapted_data, default_window, 'AA')\n",
    "    \n",
    "    adapted_data.to_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/'+str(filename)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "487f60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA-XA-LA\n",
      "CA-MB-LB\n",
      "CA-LJ-MJ\n",
      "CA-MD-GD\n",
      "CA-FB-MG\n",
      "CA-RL-ML\n",
      "CA-JL-JT\n",
      "CA-LD-GD\n",
      "CA-AN-ZN\n"
     ]
    }
   ],
   "source": [
    "for i,filename in enumerate(filenames_CA):\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    data = data_CA[i]\n",
    "    \n",
    "    adapted_data = adapt_points_3(data,\"Speaker\", \"Global_start\", \"Speech rate\")\n",
    "    \n",
    "    liste_phases = list(phases_CA[phases_CA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    adapted_data['Phases'] = find_phases(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data['Roles'] = find_roles(adapted_data['Global_start'], liste_phases)\n",
    "    adapted_data[\"Word\"] = data[\"Word\"]\n",
    "    \n",
    "    adapted_data[\"smoothed\"] = smoothed_column(adapted_data, default_window, 'CA')\n",
    "        \n",
    "    adapted_data.to_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/'+str(filename)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2d596",
   "metadata": {},
   "source": [
    "### Importing the new csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de2017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-LD-BF.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-MG-CH.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-MJ-CJ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-JL-AZ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-GD-DD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-XA-EH.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-AN-DL.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-ML-MP.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA/AA-LA-AN.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_AA = Path(\"/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/AA\").glob('**/*.csv')\n",
    "adapted_data_AA = []\n",
    "adapted_filenames_AA = []\n",
    "\n",
    "for path in pathlist_AA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        adapted_filenames_AA.append(str(path)[-12:-4])\n",
    "        adapted_data_AA.append(pd.read_csv(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91dee0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-XA-LA.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-MB-LB.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-LJ-MJ.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-MD-GD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-FB-MG.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-RL-ML.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-JL-JT.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-LD-GD.csv\n",
      "/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA/CA-AN-ZN.csv\n"
     ]
    }
   ],
   "source": [
    "pathlist_CA = Path(\"/home/inous/Documents/S2/INRIA/OUTPUT/CSV_ADAPTED/CA\").glob('**/*.csv')\n",
    "adapted_data_CA = []\n",
    "adapted_filenames_CA = []\n",
    "\n",
    "for path in pathlist_CA:\n",
    "    if \"BO\" not in str(path):\n",
    "        print(path)\n",
    "        adapted_filenames_CA.append(str(path)[-12:-4])\n",
    "        adapted_data_CA.append(pd.read_csv(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6e42d",
   "metadata": {},
   "source": [
    "### Plot of the adapted speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219df16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, axs5 = plt.subplots(9, 2, figsize=(15,20))\n",
    "\n",
    "for i, adapted_data in enumerate(adapted_data_AA) :\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Adult1\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Adult2\" ]  \n",
    "\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Adult1\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Adult2\" ]\n",
    "    \n",
    "    axs5[i,0].set_title(filename+\" speaker1\")\n",
    "    axs5[i,0].set_xlabel('Time (sec)')\n",
    "    axs5[i,0].set_ylabel('Speech rate')\n",
    "    axs5[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'], label=\"Raw\", color=my_blue)\n",
    "    axs5[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'],'o', label=\"Adapted\", color=my_red)\n",
    "    \n",
    "    axs5[i,1].set_title(filename+\" speaker2\")\n",
    "    axs5[i,1].set_xlabel('Time (sec)')\n",
    "    axs5[i,1].set_ylabel('Adapted speech rate')\n",
    "    axs5[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'],label=\"Raw\", color=my_blue)\n",
    "    axs5[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'], 'o',label=\"Adapted\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig5)\n",
    "fig5.savefig(plots_path+\"Adapted AA speech rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05b83c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, axs6 = plt.subplots(9, 2, figsize=(15,20))\n",
    "\n",
    "for i, adapted_data in enumerate(adapted_data_CA) :\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Parent\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Child\" ]  \n",
    "\n",
    "    \n",
    "    adapted_data_1 = adapted_data[ adapted_data['Speaker'] == \"Parent\" ]\n",
    "    adapted_data_2 = adapted_data[ adapted_data['Speaker'] == \"Child\" ]\n",
    "    \n",
    "    axs6[i,0].set_title(filename+\" speaker1\")\n",
    "    axs6[i,0].set_xlabel('Time (sec)')\n",
    "    axs6[i,0].set_ylabel('Speech rate')\n",
    "    axs6[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'], label=\"Raw\", color=my_blue)\n",
    "    axs6[i,0].plot(adapted_data_1['Global_start'], adapted_data_1['Speech rate'],'o', label=\"Adapted\", color=my_red)\n",
    "    \n",
    "    axs6[i,1].set_title(filename+\" speaker2\")\n",
    "    axs6[i,1].set_xlabel('Time (sec)')\n",
    "    axs6[i,1].set_ylabel('Adapted speech rate')\n",
    "    axs6[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'],label=\"Raw\", color=my_blue)\n",
    "    axs6[i,1].plot(adapted_data_2['Global_start'], adapted_data_2['Speech rate'], 'o',label=\"Adapted\", color=my_red)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.close(fig6)\n",
    "fig6.savefig(plots_path+\"Adapted CA speech rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419638b9",
   "metadata": {},
   "source": [
    "# Global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7edf1126",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for data in adapted_data_AA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "    \n",
    "    data_1 = data[data['Speaker']==speaker1]['Speech rate']\n",
    "    data_2 = data[data['Speaker']==speaker2]['Speech rate']\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(np.array(data_1), np.array(data_2))\n",
    "    correlation_list_AA.append(correlation)\n",
    "    p_values_AA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db9fd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    corr = correlation_list_AA[i]\n",
    "    p_value = p_values_AA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig7)\n",
    "fig7.savefig(plots_path+\"Global AA correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "922edbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for data in adapted_data_CA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "    \n",
    "    data_1 = data[data['Speaker']==speaker1]['Speech rate']\n",
    "    data_2 = data[data['Speaker']==speaker2]['Speech rate']\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(np.array(data_1), np.array(data_2))\n",
    "    correlation_list_CA.append(correlation)\n",
    "    p_values_CA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b2208df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig8 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    corr = correlation_list_CA[i]\n",
    "    p_value = p_values_CA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o',color=my_colors[i], label=filename)\n",
    "    plt.plot([\"p_value\"], [p_value], 'o', color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig8)\n",
    "fig8.savefig(plots_path+\"Global CA correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a96eba",
   "metadata": {},
   "source": [
    "## Global correlation with default window smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad0c4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for data in adapted_data_AA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "\n",
    "    data_1 = data[data['Speaker']==speaker1]\n",
    "    data_2 = data[data['Speaker']==speaker2]\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(smooth_2(data_1['Speech rate'], default_window, default_poly), smooth_2(data_2['Speech rate'], default_window, default_poly))\n",
    "\n",
    "    correlation_list_AA.append(correlation)\n",
    "    p_values_AA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d387dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    corr = correlation_list_AA[i]\n",
    "    p_value = p_values_AA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig9)\n",
    "fig9.savefig(plots_path+\"Global AA smoothed correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e725d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_list_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for data in adapted_data_CA :\n",
    "    \n",
    "    speaker1, speaker2 = np.unique(data['Speaker'])\n",
    "\n",
    "    data_1 = data[data['Speaker']==speaker1]\n",
    "    data_2 = data[data['Speaker']==speaker2]\n",
    "    \n",
    "    correlation, p_value = stats.pearsonr(smooth_2(data_1['Speech rate'], default_window, default_poly), smooth_2(data_2['Speech rate'], default_window, default_poly))\n",
    "\n",
    "    correlation_list_CA.append(correlation)\n",
    "    p_values_CA.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c5410e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig10 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    corr = correlation_list_CA[i]\n",
    "    p_value = p_values_CA[i]\n",
    "    plt.plot([\"correlation\"], [corr], 'o', label=filename, color=my_colors[i])\n",
    "    plt.plot([\"p_value\"], [p_value], 'o',color=my_colors[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.close(fig10)\n",
    "fig10.savefig(plots_path+\"Global CA smoothed correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9589fed",
   "metadata": {},
   "source": [
    "# Influence of the smoothing window on global correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50ff8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.arange(5, 25, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df4e7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_AA = []\n",
    "p_values_AA = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    correlation_file = []\n",
    "    p_value_file = []\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data1  = data[data['Speaker']=='Adult1']\n",
    "    data2  = data[data['Speaker']=='Adult2']\n",
    "    \n",
    "    for window in windows :\n",
    "        \n",
    "        corr, p_value = stats.pearsonr(smooth_2(data1['Speech rate'], window, default_poly), smooth_2(data2['Speech rate'], window, default_poly))\n",
    "        correlation_file.append(corr)\n",
    "        p_value_file.append(p_value)\n",
    "        \n",
    "    correlations_AA.append(correlation_file)\n",
    "    p_values_AA.append(p_value_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "764e746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig11 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "\n",
    "    plt.plot(windows, correlations_AA[i], label=filename, color=my_colors[i])\n",
    "    #plt.plot(windows, p_values_AA[i], '--',color=my_colors[i])\n",
    "\n",
    "plt.xlabel(\"smoothing window\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.legend()\n",
    "plt.close(fig11)\n",
    "fig11.savefig(plots_path+\"Window influence on correlation AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bee6b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_CA = []\n",
    "p_values_CA = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    correlation_file = []\n",
    "    p_values_file = []\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data1  = data[data['Speaker']=='Parent']\n",
    "    data2  = data[data['Speaker']=='Child']\n",
    "    \n",
    "    for window in windows :\n",
    "        \n",
    "        corr, p_value = stats.pearsonr(smooth_2(data1['Speech rate'], window, default_poly), smooth_2(data2['Speech rate'], window, default_poly))\n",
    "        correlation_file.append(corr)\n",
    "        p_values_file.append(p_value)\n",
    "        \n",
    "    correlations_CA.append(correlation_file)\n",
    "    p_values_CA.append(p_values_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "887ced86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig12 = plt.figure()\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "\n",
    "    plt.plot(windows, correlations_CA[i], label=filename, color=my_colors[i])\n",
    "    #plt.plot(windows, p_values_CA[i], \"--\", color=my_colors[i] )\n",
    "    \n",
    "plt.xlabel(\"smoothing window\")\n",
    "plt.ylabel(\"correlation\")\n",
    "plt.legend(loc=4)\n",
    "plt.close(fig12)\n",
    "fig12.savefig(plots_path+\"Window influence on correlation CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf2a3e",
   "metadata": {},
   "source": [
    "# Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd55b3e",
   "metadata": {},
   "source": [
    "## The conversation contains three phases : pregame conversation (explanation of the rules, often a monologue), the guessing game, and postgame conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afed320",
   "metadata": {},
   "source": [
    "### Computing the correlation of each phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6677fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phases = ['PREGAME', 'GAME', 'POSTGAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a63c10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA-LD-BF\n",
      "AA-MG-CH\n",
      "AA-MJ-CJ\n",
      "AA-JL-AZ\n",
      "AA-GD-DD\n",
      "AA-XA-EH\n",
      "AA-AN-DL\n",
      "AA-ML-MP\n",
      "AA-LA-AN\n"
     ]
    }
   ],
   "source": [
    "list_corr_files_AA = []\n",
    "nb_points_files_AA = []\n",
    "p_values_files_AA = []\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "\n",
    "    print(filename)\n",
    "    \n",
    "    list_corr = []\n",
    "        \n",
    "    df = pd.read_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_PHASES/AA/'+str(filename)+'.csv')\n",
    "    \n",
    "    corr_phases, nb_points, p_values = compute_corr_phases(df, Phases, \"Phases\", \"smoothed\", \"Speaker\", \"Global_start\")\n",
    "\n",
    "    p_values_files_AA.append(p_values)        \n",
    "    list_corr_files_AA.append(corr_phases)\n",
    "    nb_points_files_AA.append(nb_points)\n",
    "\n",
    "\n",
    "mean_corr = [my_mean([list_corr_files_AA[j][i] for i in range(len(list_corr_files_AA[j]))]) for j in range(len(list_corr_files_AA))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46159a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corr_files_CA = []\n",
    "nb_points_files_CA = []\n",
    "p_values_files_CA = []\n",
    "\n",
    "for i, filename in enumerate(filenames_CA):\n",
    "    list_corr = []\n",
    "        \n",
    "    file = data_CA[i]\n",
    "\n",
    "    df = pd.read_csv('/home/inous/Documents/S2/INRIA/OUTPUT/CSV_PHASES/CA/'+str(filename)+'.csv')\n",
    "    \n",
    "    corr_phases, nb_points, p_values = compute_corr_phases(df, Phases, \"Phases\", \"smoothed\", \"Speaker\", \"Global_start\")\n",
    "\n",
    "    p_values_files_CA.append(p_values)\n",
    "    list_corr_files_CA.append(corr_phases)\n",
    "    nb_points_files_CA.append(nb_points)\n",
    "\n",
    "mean_corr = [my_mean([list_corr_files_CA[j][i] for i in range(len(list_corr_files_CA[j]))]) for j in range(len(list_corr_files_CA))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471eca7c",
   "metadata": {},
   "source": [
    "### Plotting phases on the speech rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e518f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig13, axs13 = plt.subplots(9, 1, figsize=(15,20))\n",
    "\n",
    "for i, table in enumerate(data_AA) :\n",
    "    \n",
    "    filename = filenames_AA[i]\n",
    "    \n",
    "    axs13[i].set_xlabel('time')\n",
    "    axs13[i].set_ylabel('Speech rate')\n",
    "    axs13[i].plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], default_window, default_poly), label='Adult1',color = my_red)\n",
    "    axs13[i].plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], default_window, default_poly), label='Adult2', color=my_blue)\n",
    "    axs13[i].set_title(str(table['Filename'][0]))\n",
    "    axs13[i].legend()\n",
    "    \n",
    "    liste_phases = list(phases_AA[phases_AA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    for couple in liste_phases:\n",
    "        \n",
    "        label, time = couple\n",
    "\n",
    "        if \"1\" in label:\n",
    "            axs13[i].axvline(x=time, color='r')\n",
    "        elif \"2\" in label:\n",
    "            axs13[i].axvline(x=time, color='b')\n",
    "        else :\n",
    "            axs13[i].axvline(x=time, color='orange')\n",
    "            \n",
    "    if \"AA-MG-CH\" in filename:\n",
    "        fig135 = plt.figure(figsize=(20,5))\n",
    "        plt.plot(table[table['Speaker']=='Adult1']['Global_start'], smooth_2(table[table['Speaker']=='Adult1']['Speech rate'], default_window, default_poly), label='Adult1',color = my_red)\n",
    "        plt.plot( table[table['Speaker']=='Adult2']['Global_start'], smooth_2(table[table['Speaker']=='Adult2']['Speech rate'], default_window, default_poly), label='Adult2', color=my_blue)\n",
    "        \n",
    "        for couple in liste_phases:\n",
    "        \n",
    "            label, time = couple\n",
    "\n",
    "            if \"1\" in label:\n",
    "                plt.axvline(x=time, color='r')\n",
    "            elif \"2\" in label:\n",
    "                plt.axvline(x=time, color='b')\n",
    "            else :\n",
    "                plt.axvline(x=time, color='orange')\n",
    "        \n",
    "        plt.close(fig135)\n",
    "        fig135.savefig(examples_path + \"Phases_SR_AA\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.close(fig13)\n",
    "fig13.savefig(plots_path+\"Phases and smoothed speech rate AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd6b6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig14, axs14 = plt.subplots(9, 1, figsize=(15,20))\n",
    "\n",
    "for i, table in enumerate(data_CA) :\n",
    "    \n",
    "    filename = filenames_CA[i]\n",
    "    \n",
    "    axs14[i].set_xlabel('time')\n",
    "    axs14[i].set_ylabel('Speech rate')\n",
    "    axs14[i].plot(table[table['Speaker']=='Parent']['Global_start'], smooth_2(table[table['Speaker']=='Parent']['Speech rate'], default_window, default_poly), label='Parent',color = my_red)\n",
    "    axs14[i].plot( table[table['Speaker']=='Child']['Global_start'], smooth_2(table[table['Speaker']=='Child']['Speech rate'], default_window, default_poly), label='Child', color=my_blue)\n",
    "    axs14[i].set_title(str(table['Filename'][0]))\n",
    "    axs14[i].legend()\n",
    "    \n",
    "    liste_phases = list(phases_CA[phases_CA['Filename']==filename]['Phases'])[0]\n",
    "    \n",
    "    for couple in liste_phases:\n",
    "        \n",
    "        label, time = couple\n",
    "\n",
    "        if \"1\" in label:\n",
    "            axs14[i].axvline(x=time, color='r')\n",
    "        elif \"2\" in label:\n",
    "            axs14[i].axvline(x=time, color='b')\n",
    "        else :\n",
    "            axs14[i].axvline(x=time, color='orange')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.close(fig14)\n",
    "fig14.savefig(plots_path+\"Phases and smoothed speech rate CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a14501",
   "metadata": {},
   "source": [
    "### Plotting correlation of each phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7af2432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig15, axs15 = plt.subplots(3,1, figsize=(10,10))\n",
    "ax1, ax2, ax3 = axs15\n",
    "\n",
    "for i, list_corr in enumerate(list_corr_files_AA):\n",
    "    \n",
    "    ax1.plot(Phases, list_corr, 'o',label=str(filenames_AA[i]))\n",
    "    \n",
    "    ax2.plot(Phases, nb_points_files_AA[i],'o', label=str(filenames_AA[i]))\n",
    "    \n",
    "    ax3.plot(Phases, p_values_files_AA[i],'o', label=str(filenames_AA[i]))\n",
    "    \n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax2.yaxis.set_ticks_position('both')\n",
    "\n",
    "ax1.set_ylabel(\"correlation\")\n",
    "ax2.set_ylabel(\"number of utterances points\")\n",
    "ax3.set_ylabel(\"p_value\")\n",
    "\n",
    "ax1.legend(loc=(0.2, 0.05))\n",
    "ax2.legend(loc=(0.2, 0.05))\n",
    "ax3.legend(loc=(0.2, 0.05))\n",
    "\n",
    "plt.close(fig15)\n",
    "fig15.savefig(plots_path+\"Correlation by phase AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c421718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig16, axs16 = plt.subplots(3,1, figsize=(10,10))\n",
    "ax1, ax2, ax3 = axs16\n",
    "\n",
    "for i, list_corr in enumerate(list_corr_files_CA):\n",
    "    \n",
    "    ax1.plot(Phases, list_corr, 'o',label=str(filenames_CA[i]))\n",
    "    \n",
    "    ax2.plot(Phases, nb_points_files_CA[i], 'o',label=str(filenames_CA[i]))\n",
    "    \n",
    "    ax3.plot(Phases, p_values_files_CA[i],'o', label=str(filenames_CA[i]))\n",
    "    \n",
    "ax1.yaxis.set_ticks_position('both')\n",
    "ax2.yaxis.set_ticks_position('both')\n",
    "\n",
    "ax1.set_ylabel(\"correlation\")\n",
    "ax2.set_ylabel(\"number of utterances points\")\n",
    "ax3.set_ylabel(\"p_value\")\n",
    "\n",
    "ax1.legend(loc=(0.2, 0.05))\n",
    "ax2.legend(loc=(0.2, 0.05))\n",
    "ax3.legend(loc=(0.2, 0.05))\n",
    "\n",
    "plt.close(fig16)\n",
    "fig16.savefig(plots_path+\"Correlation by phase CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe28ce",
   "metadata": {},
   "source": [
    "# Correlation by game role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9ef5d",
   "metadata": {},
   "source": [
    "## Each speaker is alternatively asking or answering the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73457cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roles_AA, Correlations_AA, p_values_AA = [],[], []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "\n",
    "    filename = filenames_AA[i]\n",
    "    \n",
    "    roles, correlations, p_values = compute_corr_roles(data, \"Roles\", \"Speech rate\", \"Speaker\", \"Global_start\")\n",
    "    \n",
    "    Roles_AA.append(roles)\n",
    "    Correlations_AA.append(correlations)\n",
    "    p_values_AA.append(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f56576bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig17, axs17 = plt.subplots(3,3, figsize=(10,10))\n",
    "\n",
    "\n",
    "for i in range(len(Roles_AA)):\n",
    "\n",
    "    axs17[i//3,i%3].plot(Roles_AA[i], Correlations_AA[i], 'o')\n",
    "    axs17[i//3,i%3].set_title(filenames_AA[i])\n",
    "\n",
    "plt.close(fig17)\n",
    "fig17.tight_layout()\n",
    "fig17.savefig(plots_path+\"Correlation by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfc1fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roles_CA, Correlations_CA, p_values_CA = [],[], []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "\n",
    "    filename = filenames_CA[i]\n",
    "    \n",
    "    roles, correlations, p_values = compute_corr_roles(data, \"Roles\", \"Speech rate\", \"Speaker\", \"Global_start\")\n",
    "    \n",
    "    Roles_CA.append(roles)\n",
    "    Correlations_CA.append(correlations)\n",
    "    p_values_CA.append(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7784afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig18, axs18 = plt.subplots(3,3, figsize=(10,10))\n",
    "\n",
    "\n",
    "for i in range(len(Roles_CA)):\n",
    "\n",
    "    axs18[i//3,i%3].plot(Roles_CA[i], Correlations_CA[i], 'o')\n",
    "    axs18[i//3,i%3].set_title(filenames_CA[i])\n",
    "    \n",
    "plt.close(fig18)\n",
    "fig18.tight_layout()\n",
    "fig18.savefig(plots_path+\"Correlation by role CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95911bce",
   "metadata": {},
   "source": [
    "# Number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10939356",
   "metadata": {},
   "source": [
    "## Adult/adult vs Adult/child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d08b9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_adult_1 = []\n",
    "nb_words_adult_2 = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_AA) :\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    \n",
    "    mean_1 = np.mean(data_1[\"Word\"])\n",
    "    mean_2 = np.mean(data_2[\"Word\"])\n",
    "    \n",
    "    nb_words_adult_1.append(mean_1)\n",
    "    nb_words_adult_2.append(mean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a09ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words_adult = []\n",
    "nb_words_child = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_CA) :\n",
    "    \n",
    "    \n",
    "    data_adult = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_child = data[data[\"Speaker\"]==\"Child\"]\n",
    "        \n",
    "    mean_adult = np.mean(data_adult[\"Word\"])\n",
    "    mean_child = np.mean(data_child[\"Word\"])\n",
    "    \n",
    "    nb_words_adult.append(mean_adult)\n",
    "    nb_words_child.append(mean_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9284d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig19, axs19 = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "for i, filename in enumerate(filenames_AA):\n",
    "    \n",
    "    axs19[0].plot([\"Adult 1\", \"Adult 2\"], [nb_words_adult_1[i], nb_words_adult_2[i]], 'o', label=filename)\n",
    "    \n",
    "axs19[0].axhline(y=np.mean(nb_words_adult_1), label=\"Adult1\", color='r')\n",
    "axs19[0].axhline(y=np.mean(nb_words_adult_2), label=\"Adult2\", color='b')\n",
    "\n",
    "for j, filename in enumerate(filenames_CA):\n",
    "    \n",
    "    axs19[1].plot([\"Parent\", \"Child\"], [nb_words_adult[j], nb_words_child[j]], 'o', label=filename)\n",
    "    \n",
    "axs19[1].axhline(y=np.mean(nb_words_adult), label=\"Adult\", color='r')\n",
    "axs19[1].axhline(y=np.mean(nb_words_child), label=\"Child\", color='b')\n",
    "    \n",
    "axs19[0].set_title(\"Mean number of words for both adults\")\n",
    "axs19[1].set_title(\"Mean number of words for adult and child\")\n",
    "\n",
    "axs19[0].legend(loc=9,fontsize=8)\n",
    "axs19[1].legend(loc=9,fontsize=8)\n",
    "\n",
    "plt.close(fig19)\n",
    "fig19.savefig(plots_path+\"Mean number of words AA VS CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e22654",
   "metadata": {},
   "source": [
    "## Coding roles in a more convenient way (ask or answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57053607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    roles_file = []\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        \n",
    "        if (data[\"Speaker\"][j]==\"Adult1\" and data[\"Roles\"][j]==\"SPEAKER1 \") or (data[\"Speaker\"][j]==\"Adult2\" and data[\"Roles\"][j]==\"SPEAKER2 \"):\n",
    "            roles_file.append(\"ans\")\n",
    "            \n",
    "        else:\n",
    "            roles_file.append(\"ask\")\n",
    "            \n",
    "    data[\"New_role\"]=roles_file\n",
    "    adapted_data_AA[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd317f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    roles_file = []\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        \n",
    "        if (data[\"Speaker\"][j]==\"Parent\" and data[\"Roles\"][j]==\"SPEAKER1 \") or (data[\"Speaker\"][j]==\"Child\" and data[\"Roles\"][j]==\"SPEAKER2 \"):\n",
    "            roles_file.append(\"ans\")\n",
    "            \n",
    "        else:\n",
    "            roles_file.append(\"ask\")\n",
    "            \n",
    "    data[\"New_role\"]=roles_file\n",
    "    adapted_data_CA[i] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e724484",
   "metadata": {},
   "source": [
    "## Number of words by role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10812be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_1_ans = []\n",
    "adult_1_ask = []\n",
    "\n",
    "adult_2_ans = []\n",
    "adult_2_ask = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    \n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Word\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Word\"])\n",
    "    \n",
    "    adult_1_ans.append(mean_1_ans)\n",
    "    adult_1_ask.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Word\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Word\"])\n",
    "    \n",
    "    adult_2_ans.append(mean_2_ans)\n",
    "    adult_2_ask.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47de286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_ans = []\n",
    "adult_ask = []\n",
    "\n",
    "child_ans = []\n",
    "child_ask = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Word\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Word\"])\n",
    "    \n",
    "    adult_ans.append(mean_1_ans)\n",
    "    adult_ask.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Child\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Word\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Word\"])\n",
    "    \n",
    "    child_ans.append(mean_2_ans)\n",
    "    child_ask.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b8256b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 503.75x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker = [\"Adult 1\" for i in range(len(adult_1_ans)+len(adult_1_ask))]+[\"Adult 2\" for i in range(len(adult_2_ans)+len(adult_2_ask))]\n",
    "role = [\"Answer\" for i in range(len(adult_1_ans))] + [\"Ask\" for i in range(len(adult_1_ask))] + [\"Answer\" for i in range(len(adult_2_ans))]+ [\"Ask\" for i in range(len(adult_2_ask))]\n",
    "words = adult_1_ans + adult_1_ask + adult_2_ans + adult_2_ask\n",
    "dico_AA = {\"Speaker\":speaker, \"Role\":role,\"Words\":words}\n",
    "df_AA = pd.DataFrame(dico_AA)\n",
    "\n",
    "fig20 = sns.catplot(data=df_AA, kind=\"bar\", x=\"Role\", y=\"Words\", hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig20.despine(left=True)\n",
    "fig20.set_axis_labels(\"\", \"Mean number of words per utterance\")\n",
    "fig20.legend.set_title(\"\")\n",
    "\n",
    "fig20.savefig(plots_path+\"Mean nb of words by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd6f50b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 494.25x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker = [\"Adult\" for i in range(len(adult_ans)+len(adult_ask))]+[\"Child\" for i in range(len(child_ans)+len(child_ask))]\n",
    "role = [\"Answer\" for i in range(len(adult_ans))] + [\"Ask\" for i in range(len(adult_ask))] + [\"Answer\" for i in range(len(child_ans))]+ [\"Ask\" for i in range(len(child_ask))]\n",
    "words = adult_ans + adult_ask + child_ans + child_ask\n",
    "dico_CA = {\"Speaker\":speaker, \"Role\":role,\"Words\":words}\n",
    "df_CA = pd.DataFrame(dico_CA)\n",
    "\n",
    "fig21 = sns.catplot(data=df_CA, kind=\"bar\", x=\"Role\", y=\"Words\",hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig21.despine(left=True)\n",
    "fig21.set_axis_labels(\"\", \"Mean number of words per utterance\")\n",
    "fig21.legend.set_title(\"\")\n",
    "\n",
    "fig21.savefig(plots_path+\"Mean nb of words by role CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba1108",
   "metadata": {},
   "source": [
    "# Mean speech rate by role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53e143c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_1_ans_SR = []\n",
    "adult_1_ask_SR = []\n",
    "\n",
    "adult_2_ans_SR = []\n",
    "adult_2_ask_SR = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_AA):\n",
    "    \n",
    "    filename = adapted_filenames_AA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Adult1\"]\n",
    "    \n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Speech rate\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_1_ans_SR.append(mean_1_ans)\n",
    "    adult_1_ask_SR.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Adult2\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Speech rate\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_2_ans_SR.append(mean_2_ans)\n",
    "    adult_2_ask_SR.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c686a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_ans_SR = []\n",
    "adult_ask_SR = []\n",
    "\n",
    "child_ans_SR = []\n",
    "child_ask_SR = []\n",
    "\n",
    "for i, data in enumerate(adapted_data_CA):\n",
    "    \n",
    "    filename = adapted_filenames_CA[i]\n",
    "    \n",
    "    data_1 = data[data[\"Speaker\"]==\"Parent\"]\n",
    "    data_1_ans = data_1[data_1[\"New_role\"]==\"ans\"]\n",
    "    data_1_ask = data_1[data_1[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_1_ans = np.mean(data_1_ans[\"Speech rate\"])\n",
    "    mean_1_ask = np.mean(data_1_ask[\"Speech rate\"])\n",
    "    \n",
    "    adult_ans_SR.append(mean_1_ans)\n",
    "    adult_ask_SR.append(mean_1_ask)\n",
    "    \n",
    "    data_2 = data[data[\"Speaker\"]==\"Child\"]\n",
    "    data_2_ans = data_2[data_2[\"New_role\"]==\"ans\"]\n",
    "    data_2_ask = data_2[data_2[\"New_role\"]==\"ask\"]\n",
    "    \n",
    "    mean_2_ans = np.mean(data_2_ans[\"Speech rate\"])\n",
    "    mean_2_ask = np.mean(data_2_ask[\"Speech rate\"])\n",
    "    \n",
    "    child_ans_SR.append(mean_2_ans)\n",
    "    child_ask_SR.append(mean_2_ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0810f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 503.75x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker = [\"Adult 1\" for i in range(len(adult_1_ans_SR)+len(adult_1_ask_SR))]+[\"Adult 2\" for i in range(len(adult_2_ans_SR)+len(adult_2_ask_SR))]\n",
    "role = [\"Answer\" for i in range(len(adult_1_ans_SR))] + [\"Ask\" for i in range(len(adult_1_ask_SR))] + [\"Answer\" for i in range(len(adult_2_ans_SR))]+ [\"Ask\" for i in range(len(adult_2_ask_SR))]\n",
    "SR = adult_1_ans_SR + adult_1_ask_SR + adult_2_ans_SR + adult_2_ask_SR\n",
    "dico_AA = {\"Speaker\":speaker, \"Role\":role,\"SR\":SR}\n",
    "df_AA = pd.DataFrame(dico_AA)\n",
    "\n",
    "fig22 = sns.catplot(data=df_AA, kind=\"bar\", x=\"Role\", y=\"SR\", hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig22.despine(left=True)\n",
    "fig22.set_axis_labels(\"\", \"Mean speech rate\")\n",
    "fig22.legend.set_title(\"\")\n",
    "\n",
    "fig22.savefig(plots_path+\"Mean SR by role AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79d7d21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGoCAYAAABbrawFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXkklEQVR4nO3de7BlZXkn4N9rIxdFxUSdNpEIySgIjAWKRmVklDETFW8olYDG0qjpzEyQYEZ7tMgYMilMQiyH6ExNbI3XOJoENTKO12gBihFE6UIUb9E42tpxlCC3gALv/LF347HtPr3POb37HL5+nqpde6+11+Vtqja/833rW+ur7g4AMI47rXYBAMDuJdwBYDDCHQAGI9wBYDDCHQAGs89qF7AdQ/cBWKpa7QLWGi13ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABjMPqtdwN5o48aN2bp1a9avX59zzjlntcsBYDDCfRVs3bo1W7ZsWe0yABiUbnkAGIxwB4DBCHcAGIxr7sCaYsAprJxwB9YUA05h5XTLA8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADEa4A8BghDsADGaf1S4AgN1n48aN2bp1a9avX59zzjlntcthlQh3gIFs3bo1W7ZsWe0yWGW65QFgMMIdAAYj3AFgMMIdAAYj3AFgMMIdAAYj3AFgMMIdAAYj3AFgMMIdAAYj3AFgMMIdAAYj3AFgMMIdAAYz93CvqnVVdXlVvXfe5wIA9kzL/beTXLUHzgMAZM7hXlX3S3JiktfP8zwAwI/Mu+V+bpKNSW6b83kAgKm5hXtVPSnJd7r707vYbkNVXVZVl23atGle5QDAXmOfOR77uCRPqaonJtk/yd2r6i+6+9cWbtTdm5JsS/WeYz0AsFeYW8u9u1/W3ffr7kOSnJLko9sHOwCw+7nPHQAGM89u+dt19wVJLtgT5wKAvZ2WOwAMRrgDwGCEOwAMRrgDwGD2yIA6YG0547/85WqXsFP/73vX3/6+Vus89w9+dbVLgEVpuQPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxm6Clf1+p0kaa0BGCetNwBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGM/StcIxp48aN2bp1a9avX59zzjlntcsBWHOEO3c4W7duzZYtW1a7DIA1S7c8AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxGuAPAYIQ7AAxmpnCvqgOq6rB5FwMArNwuw72qnpxkc5IPTJePrqrz51wXALBMs7Tcz0ry8CTXJEl3b05yyLwKAgBWZp8Ztrmlu79fVXMvBmDf/Q78sXdg6WYJ9yur6plJ1lXVA5KcnuQT8y0L2FsdeuSJq13CLl386jNXu4Sduuma793+vlbrPO70s1e7hOHN0i3/wiRHJrk5yf9K8v0kZ8yxJgBgBXbZcu/uG5OcOX0BAGvcLKPlP1xVBy1YvmdVfXCuVQEAyzZLt/y9uvuabQvd/U9J7jO3igCAFZkl3G+rqp/btlBV90/S8ysJAFiJWUbLn5nk41V14XT5+CQbdrVTVe2f5KIk+03Pc153/95yCwUAZjPLgLoPVNVDkjwiSSV5UXd/d4Zj35zkhO6+vqrunMkfCO/v7k+urGQAYDGztNyTSev76un2R1RVuvuixXbo7k5y/XTxztOX7nwAmLNZRsv/cZKLM+mef8n09eJZDl5V66pqc5LvJPlwd1+yg202VNVlVXXZpk2bllI7ALADs7Tcn5bksO6+eakH7+5bkxw9vZXu3VV1VHdfud02m5JsS3UtewBYoVlGy381ky71ZZveSndBksev5DgAwK7N0nK/McnmqvpIJoPkkiTdffpiO1XVvZP8sLuvqaoDkjwuyR+vpFgAYNdmCffzp6+lum+SN1fVukx6CP6qu9+7jOMAAEswy61wb17Ogbv7iiTHLGdfAGD5dhnu02le/zDJEUn237a+u39+jnUBAMs0y4C6Nyb5n0luSfLYJG9J8tZ5FgUALN8s4X5Ad38kSXX317v7rCQnzLcsAGC5ZhlQd1NV3SnJl6vqtCRbYlY4AFizZmm5n5HkLklOT/LQJL+W5DlzrAkAWIFFW+7T29h+pbtfkslz4n99j1QFACzboi336eNjH1pVtYfqAQBWaJZr7pcneU9V/XWSG7at7O53za0qAGDZZgn3n0ryvfz4CPlOItwBYA2a5Ql1rrMDwB3ILPO5P7CqPlJVV06XH1xVvzv/0gCA5ZjlVrjXJXlZkh8mtz8z/pR5FgUALN8s4X6X7r50u3W3zKMYAGDlZgn371bVL2QyiC5VdXKSb8+1KgBg2WYZLf9bSTYlObyqtiT5WpJnzbUqVt3Frz5ztUvYqZuu+d7t72u1zuNOP3u1SwD2YrOEe3f346rqrknu1N3XVdWh8y4MAFieWbrl35kk3X1Dd183XXfe/EoCAFZipy33qjo8yZFJ7lFVT1/w1d2T7D/vwgCA5VmsW/6wJE9KclCSJy9Yf12S35hjTQDACuw03Lv7PZk8U/747r5o4XdVddzcKwMAlmWWa+7n7mDda3ZzHXuVffc7MPvuf4/su9+Bq10KAANa7Jr7I5M8Ksm9q+p3Fnx19yTr5l3YyA498sTVLgGAgS12zX3fJAdOt7nbgvXXJjl5nkUBAMu32DX3C5NcWFVv6u6v78GaAIAVmOUhNm+qqt5+ZXefsKONAYDVNUu4v3jB5/2TPCMmjgGANWuX4d7dn95u1cVVdeGc6gEAVmiX4V5VP7Vg8U5JHppk/dwqAgBWZJZu+U9nMt1rZdId/7Ukz59nUQDA8s3SLW8GOAC4A5nlCXUAwB2IcAeAwSwa7jVx8J4qBgBYuUXDvbs7yd/smVIAgN1hltHyn6yqh3X3p+ZeDQDsJvd84Bmv3Z3H+6cvnfubs2xXVScleVeSB3X3F3bw/QVJXtzdly1yjLOSXN/dr6yq5yb5UHd/a9ZaZ7nm/thMAv7vq+qKqvpsVV0x6wkAYC9zapKPJzllNx3vuUl+Zik7zNJyf8KySgGAvUxVHZjkuEwaxucnOauqDkjyxiRHJLkqyQELtr++uw+cfj45yZO6+7kLvj85ybFJ3lZV/5zkkd39z7uqY5ct9+mMcAcnOWH6+cZZ9gOAvdDTknygu7+U5OqqekiS/5Dkxu5+cJKzM3nS60y6+7wklyV5VncfPUuwJzOEdFX9XpL/nORl01V3TvIXsxYGAHuRU5O8Y/r5HdPl4zPNze6+IsncL23P0i1/UpJjknwmSbr7W1V1t7lWBQB3MFX100lOSHLUdKr0dZk8vv3y6fuOLFy//+6qZZbu9R9Mb4nrJKmqu+6ukwPAQE5O8pbuvn93H9LdB2cyH8tnkjwrSarqqCQPXrDPP1bVg6rqTpk0pnfkuiRLalTP0nL/q6p6bZKDquo3kjwvyeuWchIA2NNmvXVtNzo1yR9tt+6dmfR+HzC902xzkksXfP/SJO9N8o0kVyY5cAfHfVOSP1vKgLpZJo55ZVX9UpJrkzwwycu7+8O72g8A9ibd/ZgdrHv1LvY5L8l5O1h/1oLP78zkj4SZzdJyT5LPZjJ0v6efAYA1apbR8i/IpAvh6ZlcT/hkVT1v3oUBAMszS8v9JUmO6e7vJbePBvxEkjfMszAAYHlmGS3/zUxG6m1zXSYX/gGANWiWlvuWJJdU1Xsyueb+1CSXVtXvJEl3v2qO9QEASzRLuP/99LXNe6bvHmQDAGvQLLfC/f6eKAQAdqc3POHnd+uUr897/1dnnfJ1fZJzkzwsyc1J/iHJ3yR5Snc/aQfbvz7Jq7r781X1D0mO7e7vbrfNWZlOATtLDbPeCgcA7EJVVZJ3J3lzd58yXXd0kifvbJ/ufsHursPsbgCw+zw2yQ+7+8+2rejuzUk+luTAqjqvqr5QVW+b/iGQqrqgqo7d/kBVdWZVfbGq/jbJYUspYlkt96q6a3ffsJx9AWBgRyX59E6+OybJkUm+leTiTOZ9//iONqyqhyY5ZbrPPpk8n35nx/0Ji7bcq+pnq+rYqtp3unyfqnpFki/PegIAIElyaXd/s7tvy+QZ84cssu2jk7y7u2/s7muTnL+UE+003KvqjOnJX5PJU+mek+SqTB5DO/NE8wCwF/lcdp6RNy/4fGt23Xu+s2lid2mxlvuGJId19yOTPC2TmeBO7O4Xdfe3l3tCABjYR5PsN51FNUlSVQ9L8m+WeJyLkpxUVQdU1d2yyIC8HVnsr4abuvvqJOnu/1tVX+ruTy6xOABYFbPeurY7dXdX1UlJzq2qlya5KT+6FW4px/lMVf1lJj3oX89kQN7MFgv3+1XVwqnq7rNwubtPX8qJAGBv0N3fSvIrO/jqdQu2OW3B58cs+HzIgs9nJzl7OTUsFu4v2W555lF6AMDq2Wm4d/ebt19XVfdMck13L/siPwAwX4uNln95VR0+/bxfVX00k2fM/2NVPW5PFQgALM1io+V/NckXp5+fk6SS3DuTEX+vmHNdAMAyLRbuP1jQ/f7LSd7R3bd291XxTHoAWLMWC/ebq+qoqrp3Js/K/dCC7+4y37IAgOVarAX+20nOy6Qr/r9199eSpKqemOTyPVAbALAMi42WvyTJ4TtY/74k75tnUQDA8pnyFQAGI9wBYDDCHQAGM9MtbVX1qEzmnb19++5+y5xqAgBWYJfhXlVvTfILmcxMc+t0dScR7gCwBs3Scj82yRFLfZ58VR2cyR8A65PclmRTd//p0ksEAJZilmvuV2YS0Et1S5L/1N0PSvKIJL9VVUcs4zgAwBLM0nK/V5LPV9WlSW7etrK7n7LYTt397STfnn6+rqquSvKzST6//HIBgF2ZJdzPWulJquqQJMckuWQH321IsiFJXvva12bDhg0rPR0A7NV2Ge7dfeFKTlBVByZ5Z5IzuvvaHRx/U5JN2xZXci6Avd1Bd9nvx97ZO80yWv4RSV6T5EFJ9k2yLskN3X33Gfa9cybB/rbuftcKawVgF57zqAetdgmsAbMMqPvvSU5N8uUkByR5wXTdoqqqkvx5kqu6+1UrKRIAmN1MT6jr7q8kWTedz/2NSR4zw27HJXl2khOqavP09cTllwoAzGKWAXU3VtW+STZX1TmZjIC/66526u6PJ6kV1gcALNEsLfdnT7c7LckNSQ5O8ox5FgUALN8so+W/XlUHJLlvd//+HqgJFmU0MMDiZhkt/+Qkr8xkpPyhVXV0kv+6q4fYwLwYDQywuFm65c9K8vAk1yRJd2/OZIY4AGANmiXcb+nu78+9EgBgt5hltPyVVfXMJOuq6gFJTk/yifmWBQAs1ywt9xcmOTKTSWPenuTaJGfMsSYAYAVmGS1/Y5Izpy8AYI3babhX1fmL7Wi0PACsTYu13B+Z5BuZdMVfEk+bA4A7hMXCfX2SX8pk0phnJvk/Sd7e3Z/bE4UBAMuz0wF100liPtDdz0nyiCRfSXJBVb1wj1UHACzZogPqqmq/JCdm0no/JMmrk5iXHQDWsMUG1L05yVFJ3p/k97v7yj1WFQCwbIu13J+dySxwD0xyetXt4+kqSXf33edcGwCwDDsN9+6e5QE3AMAaI8ABYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDDCHQAGI9wBYDBzC/eqekNVfaeqrpzXOQCAnzTPlvubkjx+jscHAHZgbuHe3RcluXpexwcAdmzVr7lX1YaquqyqLtu0adNqlwMAd3j7rHYB3b0pybZU79WsBQBGsOotdwBg9xLuADCYed4K9/Ykf5fksKr6ZlU9f17nAgB+ZG7X3Lv71HkdGwDYOd3yADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADAY4Q4AgxHuADCYuYZ7VT2+qr5YVV+pqpfO81wAwMTcwr2q1iX5H0mekOSIJKdW1RHzOh8AMDHPlvvDk3ylu7/a3T9I8o4kT53j+QCAJNXd8zlw1clJHt/dL5guPzvJL3b3adtttyHJhuni/klumktBLNW9knx3tYuANcrvY235bnc/frWLWEv2meOxawfrfuIvie7elGTTHOtgGarqsu4+drXrgLXI74O1bp7d8t9McvCC5fsl+dYczwcAZL7h/qkkD6iqQ6tq3ySnJDl/jucDADLHbvnuvqWqTkvywSTrkryhuz83r/Ox27lUAjvn98GaNrcBdQDA6vCEOgAYjHAHgMEI90FV1UlV1VV1+GrXAndEs/6Gqur6PVUTzEq4j+vUJB/P5C6FVVFV83yOAszbqv+GYLmE+4Cq6sAkxyV5fqb/Y6qqx1TVBVV1XlV9oareVlU1/e6PqurzVXVFVb2yqtZV1Vdr4qCquq2qjp9u+7Gq+pdVddeqekNVfaqqLq+qp06/f25V/XVV/e8kH1qd/wKwMjv5Dd23qi6qqs1VdWVVPXq7fe5VVX9XVSeuQsnwY7SsxvS0JB/o7i9V1dVV9ZDp+mOSHJnJw4QuTnJcVX0+yUlJDu/urqqDuvvWqvpSJhP+HJrk00keXVWXJLlfd3+lql6R5KPd/byqOijJpVX1t9PzPDLJg7v76j3074Xd7Wn5yd/QY5N8sLvPnk6MdZdtG1fVv8jkOR6/290fXpWKYQEt9zGdmslEPZm+nzr9fGl3f7O7b0uyOckhSa7N5Hn+r6+qpye5cbrtx5IcP339YZJ/neRhmTycKEn+XZKXVtXmJBdkMi/Az02/+7Bg5w5uR7+hTyX59ao6K8m/6u7rpt/fOclHkmwU7KwVWu6DqaqfTnJCkqOqqjN5gFAneV+SmxdsemuSfaYPG3p4kn+bSffjadP9P5bk3yf5mSQvT/KSJI9JctG2UyV5Rnd/cbvz/2KSG+byj4M9YJHf0MZM/tg9Mclbq+pPuvstSW7JpHfrl5NcuDpVw4/Tch/PyUne0t337+5DuvvgJF/LpOX9E6bXFu/R3e9LckaSo6dfXZLkUUlu6+6bMmnp/2YmoZ9Mnjz4wgXX7Y+Zy78G9ryd/YaOT/Kd7n5dkj9Psu1yVyd5XpLDq+qlq1IxbEe4j+fUJO/ebt07kzxzJ9vfLcl7q+qKTFodL0qS7r45yTeSfHK63cem2352uvwHmXRHXlFVV06XYQQ7+w29Kcnmqro8yTOS/Om2L7v71kx6vh5bVf9xD9UJO+XxswAwGC13ABiMcAeAwQh3ABiMcAeAwQh3ABiMcAeAwQh3ABjM/wdg2xtExSDiyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 494.25x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker = [\"Adult\" for i in range(len(adult_ans_SR)+len(adult_ask_SR))]+[\"Child\" for i in range(len(child_ans_SR)+len(child_ask_SR))]\n",
    "role = [\"Answer\" for i in range(len(adult_ans_SR))] + [\"Ask\" for i in range(len(adult_ask_SR))] + [\"Answer\" for i in range(len(child_ans_SR))]+ [\"Ask\" for i in range(len(child_ask_SR))]\n",
    "SR = adult_ans_SR + adult_ask_SR + child_ans_SR + child_ask_SR\n",
    "dico_CA = {\"Speaker\":speaker, \"Role\":role,\"SR\":SR}\n",
    "df_CA = pd.DataFrame(dico_CA)\n",
    "\n",
    "fig23 = sns.catplot(data=df_CA, kind=\"bar\", x=\"Role\", y=\"SR\",hue=\"Speaker\", ci=\"sd\", palette=\"dark\", alpha=.6, height=6)\n",
    "fig23.despine(left=True)\n",
    "fig23.set_axis_labels(\"\", \"Mean SR per utterance\")\n",
    "fig23.legend.set_title(\"\")\n",
    "\n",
    "fig23.savefig(plots_path+\"Mean SR by role CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f64bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e059d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
